{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2PixHD Next Frame Prediction.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjawahar/art/blob/main/Pix2PixHD_Next_Frame_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoBaXRDKuMV"
      },
      "source": [
        "#Next Frame Prediction using Pix2PixHD\n",
        "\n",
        "By Derrick Schultz\n",
        "\n",
        "Forked repo and tutorial based on [JC Testud’s excellent repo and Medium](https://medium.com/@jctestud/video-generation-with-pix2pix-aed5b1b69f57) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2ac12f-0fd9-4a8c-e685-95d210cea089"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9D_7iUQINoa"
      },
      "source": [
        "Check to see what GPU we’re assigned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABG3hL4lIQGP",
        "outputId": "a67e7d91-b628-4bec-d130-acfa7d45adc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-7597971a-73cc-27f9-5e92-5ec81d7fa1b0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691d00f8-3d2a-4559-f82f-2155ca839dbe"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/nfp-colab/pix2pixHD/\"):\n",
        "    %cd /content/drive/MyDrive/nfp-colab/pix2pixHD/\n",
        "    # !git pull\n",
        "    !pip install dominate\n",
        "else:\n",
        "    %cd /content/drive/MyDrive\n",
        "    !mkdir nfp-colab\n",
        "    %cd nfp-colab\n",
        "    !git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "    !pip install dominate\n",
        "    %cd pix2pixHD/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/nfp-colab\n",
            "Cloning into 'pix2pixHD'...\n",
            "remote: Enumerating objects: 507, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 507 (delta 1), reused 6 (delta 1), pack-reused 501 (from 1)\u001b[K\n",
            "Receiving objects: 100% (507/507), 55.72 MiB | 13.91 MiB/s, done.\n",
            "Resolving deltas: 100% (268/268), done.\n",
            "Updating files: 100% (120/120), done.\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.9.1\n",
            "/content/drive/MyDrive/nfp-colab/pix2pixHD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive.\n",
        "\n",
        "* `-video` is the path to the video file\n",
        "* `-name` should be a unique name (think of it like a project name)\n",
        "* `-width` and `-height` **must** to be a multiple of 32\n",
        "* `-p2pdir` leave as `.` unless you know it shouldn’t be that ;)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe65f4a-5a42-4077-a666-b0d375b215f6"
      },
      "source": [
        "!python extract_frames.py -video /content/cuttlefish.mp4 -name cuttlefish -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/cuttlefish.mp4 -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/MyDrive/nfp-colab/pix2pixHD/datasets/cuttlefish/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again.\n",
        "\n",
        "*   `--name` should be a unique name (think of it like a project name). For your sanity I recommend using the same `-name` as above.\n",
        "*   `--dataroot` should point to your dataset. This will usually be in `./datasets/[your project name]`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ed25be-be67-45da-e3fc-b13744f24002"
      },
      "source": [
        "!python train_video.py --name cuttlefish --dataroot ./datasets/cuttlefish/ --save_epoch_freq 5 #--continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: False\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cuttlefish/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: cuttlefish\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 5\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_frames_before: 1\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_cres: False\n",
            "zoom_inc: 24\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/cuttlefish/train_frames\n",
            "contains 348 frames, 347 consecutive pairs\n",
            "#training images = 347\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:05<00:00, 107MB/s] \n",
            "create web directory ./checkpoints/cuttlefish/web...\n",
            "/content/drive/MyDrive/nfp-colab/pix2pixHD/models/networks.py:97: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
            "(epoch: 1, iters: 100, time: 2.231) G_GAN: 2.182 G_GAN_Feat: 8.750 G_VGG: 4.602 D_real: 1.306 D_fake: 1.337 \n",
            "(epoch: 1, iters: 200, time: 2.281) G_GAN: 1.140 G_GAN_Feat: 6.754 G_VGG: 3.683 D_real: 0.301 D_fake: 0.289 \n",
            "(epoch: 1, iters: 300, time: 2.278) G_GAN: 1.369 G_GAN_Feat: 6.958 G_VGG: 3.184 D_real: 0.624 D_fake: 0.480 \n",
            "End of epoch 1 / 200 \t Time Taken: 785 sec\n",
            "(epoch: 2, iters: 53, time: 2.280) G_GAN: 0.940 G_GAN_Feat: 6.402 G_VGG: 5.310 D_real: 0.398 D_fake: 0.438 \n",
            "(epoch: 2, iters: 153, time: 2.278) G_GAN: 0.960 G_GAN_Feat: 7.917 G_VGG: 6.328 D_real: 0.550 D_fake: 0.431 \n",
            "(epoch: 2, iters: 253, time: 2.277) G_GAN: 1.951 G_GAN_Feat: 7.482 G_VGG: 3.218 D_real: 0.558 D_fake: 0.246 \n",
            "End of epoch 2 / 200 \t Time Taken: 790 sec\n",
            "(epoch: 3, iters: 6, time: 2.277) G_GAN: 1.537 G_GAN_Feat: 7.475 G_VGG: 2.371 D_real: 0.334 D_fake: 0.524 \n",
            "(epoch: 3, iters: 106, time: 2.279) G_GAN: 1.148 G_GAN_Feat: 5.274 G_VGG: 2.049 D_real: 0.196 D_fake: 0.282 \n",
            "(epoch: 3, iters: 206, time: 2.280) G_GAN: 1.779 G_GAN_Feat: 5.876 G_VGG: 2.005 D_real: 0.213 D_fake: 0.047 \n",
            "(epoch: 3, iters: 306, time: 2.281) G_GAN: 1.188 G_GAN_Feat: 5.625 G_VGG: 2.134 D_real: 0.282 D_fake: 0.344 \n",
            "saving the latest model (epoch 3, total_steps 1000)\n",
            "End of epoch 3 / 200 \t Time Taken: 797 sec\n",
            "(epoch: 4, iters: 59, time: 2.282) G_GAN: 0.845 G_GAN_Feat: 8.343 G_VGG: 4.691 D_real: 0.228 D_fake: 0.529 \n",
            "(epoch: 4, iters: 159, time: 2.279) G_GAN: 1.229 G_GAN_Feat: 11.312 G_VGG: 5.452 D_real: 0.499 D_fake: 0.187 \n",
            "(epoch: 4, iters: 259, time: 2.281) G_GAN: 0.612 G_GAN_Feat: 5.563 G_VGG: 2.000 D_real: 0.221 D_fake: 0.567 \n",
            "End of epoch 4 / 200 \t Time Taken: 791 sec\n",
            "(epoch: 5, iters: 12, time: 2.279) G_GAN: 1.840 G_GAN_Feat: 7.078 G_VGG: 1.770 D_real: 0.243 D_fake: 0.121 \n",
            "(epoch: 5, iters: 112, time: 2.281) G_GAN: 1.901 G_GAN_Feat: 10.760 G_VGG: 5.144 D_real: 0.195 D_fake: 0.115 \n",
            "(epoch: 5, iters: 212, time: 2.280) G_GAN: 0.785 G_GAN_Feat: 7.706 G_VGG: 4.154 D_real: 0.101 D_fake: 0.371 \n",
            "(epoch: 5, iters: 312, time: 2.281) G_GAN: 0.883 G_GAN_Feat: 9.653 G_VGG: 5.083 D_real: 0.228 D_fake: 0.683 \n",
            "End of epoch 5 / 200 \t Time Taken: 791 sec\n",
            "saving the model at the end of epoch 5, iters 1735\n",
            "(epoch: 6, iters: 65, time: 2.374) G_GAN: 0.639 G_GAN_Feat: 5.808 G_VGG: 1.687 D_real: 0.134 D_fake: 0.535 \n",
            "(epoch: 6, iters: 165, time: 2.281) G_GAN: 1.450 G_GAN_Feat: 10.724 G_VGG: 5.285 D_real: 0.195 D_fake: 0.129 \n",
            "(epoch: 6, iters: 265, time: 2.282) G_GAN: 0.915 G_GAN_Feat: 7.618 G_VGG: 4.632 D_real: 0.666 D_fake: 0.391 \n",
            "saving the latest model (epoch 6, total_steps 2000)\n",
            "End of epoch 6 / 200 \t Time Taken: 795 sec\n",
            "(epoch: 7, iters: 18, time: 2.283) G_GAN: 0.602 G_GAN_Feat: 4.583 G_VGG: 1.499 D_real: 0.055 D_fake: 0.468 \n",
            "(epoch: 7, iters: 118, time: 2.280) G_GAN: 2.466 G_GAN_Feat: 8.961 G_VGG: 1.813 D_real: 0.280 D_fake: 0.067 \n",
            "(epoch: 7, iters: 218, time: 2.279) G_GAN: 1.896 G_GAN_Feat: 6.525 G_VGG: 3.874 D_real: 0.109 D_fake: 0.085 \n",
            "(epoch: 7, iters: 318, time: 2.277) G_GAN: 1.726 G_GAN_Feat: 5.407 G_VGG: 1.443 D_real: 0.400 D_fake: 0.164 \n",
            "End of epoch 7 / 200 \t Time Taken: 790 sec\n",
            "(epoch: 8, iters: 71, time: 2.278) G_GAN: 1.373 G_GAN_Feat: 5.997 G_VGG: 1.517 D_real: 0.058 D_fake: 0.147 \n",
            "(epoch: 8, iters: 171, time: 2.277) G_GAN: 1.804 G_GAN_Feat: 8.406 G_VGG: 4.181 D_real: 0.348 D_fake: 0.035 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD"
      },
      "source": [
        "### Continue Training\n",
        "To pick up from a previous training session run the same command you ran to start with and append `--continue_train` to the end of the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg",
        "outputId": "3feb6201-7c30-46c7-d1be-d91d69c9b32a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python train_video.py --name cuttlefish1 --dataroot ./datasets/cuttlefish1/ --save_epoch_freq 1 --continue_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cuttlefish1/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: cuttlefish1\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 1\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_frames_before: 1\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_cres: False\n",
            "zoom_inc: 24\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 1 at iteration 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/train_video.py\", line 55, in <module>\n",
            "    opt.print_freq = lcm(opt.print_freq, opt.batchSize) \n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/train_video.py\", line 11, in lcm\n",
            "    def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
            "                                    ^^^^^^^^^^^^^\n",
            "AttributeError: module 'fractions' has no attribute 'gcd'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2"
      },
      "source": [
        "#Generating Videos\n",
        "\n",
        "To generate a video from your completed model, run the `generate_video.py` script. I recommend keeping the `--name` and `--dataroot` arguments the same.\n",
        "\n",
        "There are a number of additional arguments you’ll need to include in this command:\n",
        "\n",
        "\n",
        "*   `--fps` frame rate for your video\n",
        "*   `--how_many` how many frames you want to create (this + fps = video length)\n",
        "*   `--which_epoch` which epoch you want to generate videos from (note: if you choose `133` but there’s no epoch 133 model file, this will throw an error)\n",
        "*   `--start_from` by default your video will start predicting images from the 60th frame of your training set. You can pass in the path to a different frame to have it start from that frame\n",
        "\n",
        "I recommend playing with both the `--which_epoch` and `--start_from` arguments as you can get dramatically different results by changing in the inputs here.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVUtG-pt_F6",
        "outputId": "b0f7ba85-acca-4674-f799-3255999d9bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python generate_video.py --name cityscapes --dataroot ./datasets/cityscapes/ --fps 24 --how_many 600 --which_epoch latest"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "how_many: 600\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: cityscapes\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_crop: True\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "png: False\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_frames_before: 1\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_cres: False\n",
            "zoom_inc: 24\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/generate_video.py\", line 28, in <module>\n",
            "    data_loader = CreateDataLoader(opt)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/data/data_loader.py\", line 6, in CreateDataLoader\n",
            "    data_loader.initialize(opt)\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/data/custom_dataset_data_loader.py\", line 25, in initialize\n",
            "    self.dataset = CreateDataset(opt)\n",
            "                   ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/data/custom_dataset_data_loader.py\", line 16, in CreateDataset\n",
            "    dataset.initialize(opt)\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/data/frame_dataset.py\", line 16, in initialize\n",
            "    self.frame_paths = sorted(make_dataset(self.dir_frames))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/nfp-colab/pix2pixHD/data/image_folder.py\", line 23, in make_dataset\n",
            "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: ./datasets/cityscapes/test_frames is not a valid directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiaLMDmdDG3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2191c96c-03fa-48e1-8013-ab130e6df9e0"
      },
      "source": [
        "import os\n",
        "\n",
        "def processFolder(folder, epoch = 10, frameCount = 240, skipCount = 1):\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  count = 0\n",
        "  for f in files:\n",
        "\n",
        "    if (count % skipCount == 0):\n",
        "      print(f)\n",
        "      if epoch == 'latest':\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 60 --how_many %i --which_epoch latest --start_from %s/%s' % ( frameCount, folder, f)\n",
        "      else:\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 24 --how_many %i --which_epoch %i --start_from %s/%s' % ( frameCount, epoch, folder, f)\n",
        "      os.system(command)\n",
        "    count += 1\n",
        "\n",
        "processFolder('./datasets/fuck-white/train_frames',1,600,3050)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame-018504.jpg\n",
            "frame-015525.jpg\n",
            "frame-012746.jpg\n",
            "frame-009603.jpg\n",
            "frame-006972.jpg\n",
            "frame-004082.jpg\n",
            "frame-001186.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}